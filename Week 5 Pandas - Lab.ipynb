{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Week 5 Pandas - Lab.ipynb","provenance":[{"file_id":"17LLycw-lIo70lRQqlNVrL1Zv9hRqxSh7","timestamp":1633498129393}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"UXoh3by3E1G8"},"source":["# Week 5: Data Analysis Using NumPy and Pandas 2"]},{"cell_type":"markdown","metadata":{"id":"lKlBA1YgE1HA"},"source":["## 1.Pandas Basics\n","\n","Pandas는 numpy 기반으로 개발된 자료구조이다.\n","R과 비슷한 데이터프레임과 이를 조작하기 위한 메소드를 제공한다."]},{"cell_type":"markdown","metadata":{"id":"ra0C6e6XE1HA"},"source":["Pandas를 사용하기 위해서 다음과 같이 라이브러리를 import 한다. numpy도 주로 같이 사용하니 같이 import 한다."]},{"cell_type":"code","metadata":{"id":"Te0qmJwxE1HB"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DdgcLWTrJ6aU"},"source":["### 1.1 Pandas의 자료구조\n","\n","Pandas는 Series와 DataFrame 이라는 두개의 자료구조를 제공한다."]},{"cell_type":"markdown","metadata":{"id":"RRB2xU9-KGqI"},"source":["#### Series\n","Series는 요소(객체)를 담을 수 있는 1차원 배열 자료구조."]},{"cell_type":"code","metadata":{"id":"t-Yrfa9IKPAl"},"source":["a = pd.Series([1, 2, 3, 4])\n","a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmY0F5EKKZ3h"},"source":["a.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VzNZ1L1KKeI1"},"source":["a.index"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M7X9_IETFV62"},"source":["#### DataFrame\n","DataFrame은 스프레드시트의 표같은 형식의 자료구조로 여러 column으로 구성되어 있다. 각각의 컬럼은 다른 형식의 데이터를 담을 수 있다."]},{"cell_type":"code","metadata":{"id":"Wcdi2KQzKn9P"},"source":["data = {  \n","    'state':[\"PA\", \"NY\", \"CO\", \"CA\"],  \n","    'population':[100, 200, 300, 400],  \n","    'size':[10, 20, 30, 40]\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ICZJh-4KyHs"},"source":["b = pd.DataFrame(data)\n","b"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"55x7vaBdE1HB"},"source":["### 1.2 Reading Data\n","\n","Pandas는 `read_csv()`라는 CSV 파일을 읽어주는 함수를 제공합니다.\n","\n","(참고) Excel 파일을 읽는 함수도 제공합니다. `ExcelFile(), read_excel()`\n","```\n","* df = pd.ExcelFile(\"dummydata.xlsx\")\n","* df = pd.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')\n","```"]},{"cell_type":"code","metadata":{"id":"bAKTQggKMEeL"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2KTdkJLE1HC"},"source":["data = pd.read_csv(\"/content/drive/MyDrive/_SocialComp_2022-Lab/Week5/weather_year.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"12wD9UcZE1HD"},"source":["data\n","len(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ibsRkYhfE1HE"},"source":["columns 명령어는 데이터의 column을 보여준다. "]},{"cell_type":"code","metadata":{"id":"wWieEOcgE1HE"},"source":["data.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OIP4xJQ-E1HF"},"source":["특정 column을 읽어오려면 다음과 같이 사용한다."]},{"cell_type":"code","metadata":{"id":"qMz7bgt6E1HG"},"source":["data['EDT']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F1wq8G1TE1HG"},"source":["Array를 이용하여 여러개의 column을 불러올 수도 있다."]},{"cell_type":"code","metadata":{"id":"hT4fON2EE1HG"},"source":["data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EZfywGnxE1HG"},"source":["`describe()` 명령어는 기초 통계값을 보여준다. 다만 숫자 데이터에만 적용된다."]},{"cell_type":"code","metadata":{"id":"VQvDD0TWE1HH"},"source":["data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']].describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hM3jamMRE1HH"},"source":["만약 column 이름에 공백이 없다면, **```data.column_name```** 형태로 사용할 수 있다."]},{"cell_type":"code","metadata":{"id":"TkXUFlypE1HH"},"source":["data.EDT # only works when the column name has no space"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-82zYnvAE1HI"},"source":["`head()`는 처음 다섯개의 샘플 데이터를 보여준다. 데이터가 어떻게 생겼는지 파악할 때 큰 도움이 된다."]},{"cell_type":"code","metadata":{"id":"RRdvsbGnE1HI"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8_BA1fm0E1HI"},"source":["`data.head(num)`는 원하는 수 num 만큼의 데이터를 보여준다."]},{"cell_type":"code","metadata":{"id":"gZ8HTMLwE1HI"},"source":["data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']].head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fv9xFALDE1HI"},"source":["`tail()` 함수는 `head()`와 반대로 맨 아래 다섯개의 데이터를 보여\u001d준다."]},{"cell_type":"code","metadata":{"id":"k2vTlNwZE1HI"},"source":["data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']].tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AbQ7uKKzE1HJ"},"source":["다시 columns 를 출력해보자."]},{"cell_type":"code","metadata":{"id":"cIF_-JOME1HJ"},"source":["data.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0EmtOGqIE1HJ"},"source":["columns의 이름을 살펴보니 단어 중간이나 앞부분에 공백이 있기도 하고 너무 길어서 데이터 처리에 불편하다. 그래서 다음과 같은 방법으로 columns의 이름을 고쳐보도록 하자. "]},{"cell_type":"code","metadata":{"id":"EtlryCDzE1HJ"},"source":["data.columns = [\"date\", \"max_temp\", \"mean_temp\", \"min_temp\", \"max_dew\",\n","                \"mean_dew\", \"min_dew\", \"max_humidity\", \"mean_humidity\",\n","                \"min_humidity\", \"max_pressure\", \"mean_pressure\",\n","                \"min_pressure\", \"max_visibilty\", \"mean_visibility\",\n","                \"min_visibility\", \"max_wind\", \"mean_wind\", \"min_wind\",\n","                \"precipitation\", \"cloud_cover\", \"events\", \"wind_dir\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"abhfpFq8E1HJ"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHlF8SIJOUKJ"},"source":["column의 이름을 바꿀 때는 원래의 column의 숫자와 동일하게 이름의 array를 만들어줘야 한다. 그렇지 않으면 에러가 발생."]},{"cell_type":"code","metadata":{"id":"WVborv8NE1HJ"},"source":["data.min_temp.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxkD4zXFE1HK"},"source":["data.min_temp.std()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HzxIqihzE1HK"},"source":["Pandas는 자체적으로 matplotlib을 지원한다. 따라서 간단하게 데이터의 그래프를 그릴 수 있다."]},{"cell_type":"markdown","metadata":{"id":"OSZolRnHE1HK"},"source":["Jupyter Notebook에서 그래프를 보이게 하려면 다음과 같은 명령어를 입력한다. (CoLab 에서는 필요 없는 듯)\n","\n","`%matplotlib inline`"]},{"cell_type":"code","metadata":{"id":"SEXBxbJUE1HK"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt  \n","\n","# 이 코드에서 실제로 plt 는 사용하지 않지만, 후에 matplotlob.pyplot를 이용해 그림을 그린다면 필요"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uNvGnqD7E1HK"},"source":["data.min_temp.hist() # min_temp 전체 값의 histogram"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8KzKZhwE1HK"},"source":["data.min_temp.plot() # min_temo 전체 값의 추이 라인그래프"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m880PaxvE1HK"},"source":["data.std() # 모든 데이터의 표준편차"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqUO0M_IPO7C"},"source":["data.mean() # 모든 데이터의 평균값"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MX_5OX54E1HK"},"source":["### 1.3 Bulk Data Clean Up\n","\n","이번에는 `apply()`함수를 사용하여 column 내의 데이터를 한꺼번에 변경하는 방법을 사용해보자. 데이터의 클린업 과정에서 매우 빈번하게 사용되는 명령어."]},{"cell_type":"code","metadata":{"id":"saBKwIJ6E1HK"},"source":["data.date.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bTK-uAHE1HL"},"source":["first_date = data.date.values[0]\n","type(first_date)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"morPmA9UE1HL"},"source":["현재 data.date에 담긴 값들은 date 형식의 데이터가 아니라 str 형태이다. 날짜 계산 등을 위해서는 str 로 저장된 데이터의 형식을 datetime 형식으로 변환해야 한다. \n","\n","지난 번에 배웠던 명령어로 `strftime()` 라는 게 있었다. 이 함수는 date 형식의 데이터의 포맷을 변경하는 함수였다. str 을 datetime 으로 바꾸기 위해서는 `strptime()`이라는 함수를 사용한다. 사용법은 유사하다."]},{"cell_type":"code","metadata":{"id":"9d9MBTybE1HL"},"source":["from datetime import datetime\n","datetime.strptime(first_date, \"%Y-%m-%d\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"amYxxsvtE1HL"},"source":["그런데, 이렇게 데이터를 일일히 하나하나 바꾸어줄 수는 없다. data.date 에 있는 모든 값을 한꺼번에 다 datetime 포맷으로 바꿀 수 있다면 좋을 것 같다.\n","\n","파이썬은 `lambda` 라는 함수를 제공하고 있는데, 한번 쓰고 버리는 일시적인 함수이다. 예전 시간에 `def ..` 등을 이용하여 함수를 만드는 방법을 소개했었는데, 이렇게 함수를 만들어 두고 계속 사용하는 것이 아니라, 필요한 곳에서 즉시 사용하고 버리는 함수.\n","\n","`lambda`함수는 `apply()`와 함께 사용할 때 시너지 있다. `apply()` 모든 column에 한꺼번에 `lambda`함수를 적용하게 적용하게 한다. 즉, `lambda`와 `apply()`를 사용해서 데이터의 형을 일괄적으로 바꿀 수 있다."]},{"cell_type":"code","metadata":{"id":"nd7S4CReE1HL"},"source":["# (참고) lambda 의 사용법\n","function = lambda x: x*5\n","function(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Krjx3-IvR-_u"},"source":["def multi5(x):\n","  x = x*5\n","  return x\n","\n","multi5(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfvCDc9OE1HL"},"source":["data.date = data.date.apply(lambda d: datetime.strptime(d, \"%Y-%m-%d\"))\n","data.date.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SMni6kNZE1HL"},"source":["현재 우리 데이터의 각각의 row의 index는 `0 ~ len(data)`의 integer가 자동으로 지정되었다. 만약 데이터의 index를 다른 컬럼으로 (예를 들어 date) 지정하고 싶으면 index 명령어를 사용한다."]},{"cell_type":"code","metadata":{"id":"_1-B2cfkE1HL"},"source":["data.index = data.date\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnwOD8I_E1HL"},"source":["이제 날짜를 이용해서 특정 데이터를 검색할 수 있다."]},{"cell_type":"code","metadata":{"id":"_GIWGN-hE1HL"},"source":["data.loc[datetime(2012, 8, 22)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_8XwtC8E1HM"},"source":["불필요한 컬럼을 삭제하기 위해서는 `drop()` 명령어를 사용한다. 위의 데이터에서는 date를 index로 지정하였기 때문에 데이터 테이블 내의 date는 이제 필요없어졌다. (현재 중복되어 있음). 불필요하게 중복된 데이터 컬럼은 다음과 같이 삭제한다. \n"]},{"cell_type":"code","metadata":{"id":"O66JA8SYE1HM"},"source":["data = data.drop([\"date\"], axis=1)\n","data.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_fOTk93E1HM"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b3qZGRcNE1HM"},"source":["axis=1 은 column에 적용됨을 의미한다. 0은 row에 1은 column에 적용된다고 생각하면 된다. \n","http://stackoverflow.com/questions/25773245/ambiguity-in-pandas-dataframe-numpy-array-axis-definition"]},{"cell_type":"markdown","metadata":{"id":"cBnl1CwnE1HM"},"source":["### 1.4 Missing Values (결측값)\n","\n","데이터에 missing value 가 있다. missing value 를 처리해보\u001d자. missing value를 처리하는 정답은 없다. missing value가 포함된 데이터 포인트가 그렇게 많지 않다면 데이터 포인트를 단순히 삭제를 해도 좋을 것 같다. 그러나 missing data가 많다면 처리 방법을 결정해야 한다. 0 과 같은 값으로 채워 넣는 방법도 있고 평균값을 넣는 경우도 있으며, 최근에는 machine learning을 이용해 값을 추정해서 넣기도 한다. missing value의 처리는 데이터 분석 결과에 큰 영향을 미칠 수 있으므로 데이터의 속성을 잘 파악한 후 결정해야 한다."]},{"cell_type":"markdown","metadata":{"id":"_aIl6XurUc0m"},"source":["`isnull()`이라는 함수는 값이 없을 때 (null일 때) True를 반환한다. 따라서 전체 dataframe의 모든 값을 대상으로 `isnull()` 함수를 적용하면 다음과 같다."]},{"cell_type":"code","metadata":{"id":"2qBYJrPZE1HM"},"source":["empty = data.apply(lambda col: pd.isnull(col))\n","empty"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sa1l5mzmU2Eh"},"source":["중간에 생략된 row가 많긴 하지만 대부분의 column은 missing value가 없는 것으로 보\u001d다. 다만, events column에 True가 많이 보인다. events column 을 좀더 살펴보자."]},{"cell_type":"code","metadata":{"id":"VyyjhdzlE1HM"},"source":["empty.events.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"30YAwbT2VH9P"},"source":["empty 데이터프레임은 missing value 가 있는지 없는지만을 파악할 수 있기 때문에 실제 저장된 값은 무엇인지 살펴보도록 하자."]},{"cell_type":"code","metadata":{"id":"_ICpVYbnE1HM"},"source":["data.events.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CwKxLjWxVY8k"},"source":["events 에는 그날의 날씨가 Rain, Thunderstorm, Fog 등의 형태로 기록되어 있다. 아마 특이한 사항이 없는 날은 기록하지 않은 것 같다. missing value인 데이터가 전부 얼마나 되는지 살펴보자."]},{"cell_type":"code","metadata":{"id":"n9iaIalQE1HM"},"source":["len(empty[empty.events == True])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U0qjK6CIE1HM"},"source":["missing value를 처리하는 한가지 방법은 해당 데이터 포인트를 삭제하는 것이라고 앞서 언급했다. pandas에는 `dropna()`라는 함수가 있어서 이 함수를 사용하면 데이터가 입력되지 않은 row, 즉 위의 데이터에서 events가 NaN인 경우 모두 삭제를 할 수 있다. 그러나, 이렇게 삭제를 하게되면 전체 366개의 데이터 중 162개 밖에 남지 않\u001d는다. 따라서 이렇게 missing value가 많은 경우 삭제하는 것 보다는 다르게 처리하는 편이 좋겠다. \n","\n","현재 events는 숫자 데이터가 아닌 문자 데이터를 담고 있다. 따라서 NaN 대신 빈 문자열을 채워 넣어보자. 이때 사용하는 함수는 `fillna()`이다."]},{"cell_type":"code","metadata":{"id":"KrBo2k1SE1HN"},"source":["data.events = data.events.fillna(\"\")\n","data.events.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mSWYNi9iWauA"},"source":["NaN이 모두 빈 문자열(`''`라고 표현)으로 바뀌었다."]},{"cell_type":"markdown","metadata":{"id":"xNbU4G8NE1HN"},"source":["### 1.5 Accessing Rows\n","\n","이제 데이터 분석을 위한 준비를 거의 마쳤다. 데이터 분석의 첫 단계는 데이터를 훑어보는 것이다. 그러기 위해서는 데이터의 일부를 뽑아보는 것이 좋겠다.\n","\n","데이터의 row (데이터 포인트) 를 살펴보기 위한 여러 함수가 있는데 파이썬에서 기본적으로 list 의 내용을 살펴보는 방법과 유사하다."]},{"cell_type":"code","metadata":{"id":"EAOX5bUKE1HN"},"source":["data.iloc[0] # 하나의 데이터 포인트 탐색"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9phsQ1c5E1HN"},"source":["data.iloc[3:9] # 인덱스 3-9까지 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZuKe-j7lE1HN"},"source":["ㅁㅁdata.loc[datetime(2012, 3, 15)] # 날짜로 검색"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LD-7R_4pE1HN"},"source":["`iterrows()`함수는 데이터프레임의 row를 iterate하게 한다. (for loop를 이용하여 한 row 씩 처리하게 함.)"]},{"cell_type":"code","metadata":{"id":"dhgNWHEwE1HN"},"source":["num_rain = 0\n","for idx, row in data.iterrows():\n","    if \"Rain\" in row[\"events\"]:\n","        num_rain += 1\n","\n","\"Days with rain: {0}\".format(num_rain)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jCJKQdrAE1HN"},"source":["### 1.6 Filtering\n","\n","Filtering은 데이터를 살펴보고 분석을 할 때 가장 좋은 방법이다. Filtering을 하기 위한 방법들을 살펴보자."]},{"cell_type":"code","metadata":{"id":"QKHHdJC2E1HN"},"source":["freezing_days = data[data.max_temp <= 32]\n","freezing_days"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oT3VSPsnE1HN"},"source":["freezing_days[freezing_days.min_temp >= 20]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ebaxdM3E1HO"},"source":["data[(data.max_temp <= 32) & (data.min_temp >= 20)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CFYBwY08E1HO"},"source":["필터를 변수 형태로 만들어 놓고 사용하는 것도 물론 가능하다."]},{"cell_type":"code","metadata":{"id":"Ge1AkLOvE1HO"},"source":["# max_temp 가 32보다 작거나 같은 경우의 필터를 생성\n","temp_max = data.max_temp <= 32\n","temp_max"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYoxz7tfE1HO"},"source":["data[temp_max]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewp0Ljn6E1HO"},"source":["# max_temp 가 20보다 크거나 같은 경우의 필터를 생성\n","temp_min = data.min_temp >= 20\n","temp_min"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1MoFttIE1HO"},"source":["temp_min & temp_max"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ea4yT_haE1HR"},"source":["temp_min | temp_max"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K5rDUkcPE1HR"},"source":["두개의 필터를 이용해서 새로운 필터를 만들어 둘 수도 있다."]},{"cell_type":"code","metadata":{"id":"owdguiGsE1HR"},"source":["temp_both = temp_min & temp_max"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zPpkeRTXE1HR"},"source":["숫자가 아닌 경우는 filter를 이런 식으로 만들 수 없다. 다음과 같은 코드는 data.events의 각 row를 iterate하며 Rain이 포함되어 있는지 여부를 판단할 것 같지만 그렇지 않다. 이 코드는 에러를 발생."]},{"cell_type":"code","metadata":{"id":"y1JbM1CwE1HR"},"source":["data[\"Rain\" in data.events]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nq6lqmr1E1HR"},"source":["이 경우, 다음과 같이 lambda 함수와 apply 함수를 사용해 filter를 만들어야 한다."]},{"cell_type":"code","metadata":{"id":"6gGtj4MtE1HR"},"source":["data[data.events.apply(lambda e: \"Rain\" in e)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"332yPRusE1HR"},"source":["### 1.7 Grouping\n","\n","`apply()`만큼 유용하게 쓸 수 있는 함수 중에 `groupby()`가 있다. 이 함수는 dataframe에서 같은 값을 갖는 데이터 포인트를 찾아서 묶어\u001d준다."]},{"cell_type":"markdown","metadata":{"id":"DG95LZGqE1HS"},"source":["예를 들어 cloud_cover 데이터를 추출하면 다음과 같이 0-8까지의 값이 기록되어 있다. cloud_cover 란 말 그대로 얼마나 하늘이 구름으로 덮여있는지를 말하는 건데, 전혀 덮혀있지 않은 0에서부터 구름으로 가득 낀 하늘의 상태인 8 까지 기록되어 있다. \n","\n","만약 구름이 하나도 없을 때와, 잔뜩 덮혀 있을 때의 평균 온도/습도를 비교하고 싶다면 아마도 cloud_cover 의 값으로 데이터를 grouping 해야할 것이다. `groupby()`는 이럴 때 쓸 수 있다."]},{"cell_type":"code","metadata":{"id":"IvLmkxjpE1HS"},"source":["data.cloud_cover"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D53dpIytE1HS"},"source":["data.cloud_cover.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-Tx_o8EE1HS"},"source":["for d in data.groupby(\"cloud_cover\"):\n","    print(d)\n","    print(\"===\")\n","\n","# 결과는 tuple 형태로 출력된다. \n","# d[0] -> cloud_cover level\n","# d[1] -> 각 cloud_cover level이 포함된 data row\n","# 여기서 loop는 각 data row의 iteration을 가져오는게 아니라 group의 iteration을 가져온다."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bLSUqZklaZ_f"},"source":["데이터의 컬럼이 너무 많아 한눈에 보기 어려우니 각 날짜의 평균온도(mean_temp)만 뽑아보겠습니다."]},{"cell_type":"code","metadata":{"id":"YVKX1L0GaiAo"},"source":["for d in data.groupby(\"cloud_cover\").mean_temp:\n","    print(d)\n","    print(\"===\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iClfKwEWE1HS"},"source":["출력되는 tuple 값을 이용해서 각 그룹의 평균온도(mean_temp)의 평균을 다음과 같이 구해보자."]},{"cell_type":"code","metadata":{"id":"PhRfY0QHE1HS"},"source":["cover_temps = {}\n","for cover, cover_data in data.groupby(\"cloud_cover\"):\n","    cover_temps[cover] = cover_data.mean_temp.mean()\n","cover_temps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-mFbAm9GE1HS"},"source":["한개 이상의 컬럼을 이용해서 데이터를 groupby 할 수도 있다. 이 경우, 두개의 컬럼의 값이 tuple 로 먼저 출력되고, 그 다음에 data row 가 출력된다."]},{"cell_type":"code","metadata":{"id":"vskcqDRgE1HS"},"source":["for (cover, events), group_data in data.groupby([\"cloud_cover\", \"events\"]):\n","    print(\"Cover: {}, Events: {}, Count: {}\".format(cover, events, len(group_data)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cWA2w1QCE1HS"},"source":["### 1.8 Adding New Columns"]},{"cell_type":"markdown","metadata":{"id":"Txz-BgmiE1HS"},"source":["다시 events 컬럼의 데이터를 살펴보자."]},{"cell_type":"code","metadata":{"id":"2vu6uaoyE1HS"},"source":["data.events.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JeMf8R7FE1HS"},"source":["여러 데이터가 있지만, 기본적으로는 rain, thunderstorm, fog, snow 의 네가지의 조합으로 이루어져 있다. 이 데이터를 바탕으로 특정일에 비가 왔는지, 안개가 끼었는지 등을 확인하고 싶어서 새롭게 컬럼을 추가하고자 한다. rain, thunderstorm, fog, snow의 컬럼을 만들고 True or False를 저장하도록 하자. (One Hot Coding)\n","* Rain-Thunderstorm => rain:True, thunderstorm:True, fog:False, snow:False\n","* Fog-Rain-Thunderstorm => rain:False, thunderstorm:True, fog:True, snow:False"]},{"cell_type":"code","metadata":{"id":"k-BFtdQSE1HS"},"source":["for event_kind in [\"Rain\", \"Thunderstorm\", \"Fog\", \"Snow\"]:\n","    col_name = event_kind.lower()  # Turn \"Rain\" into \"rain\", etc. -> data normalization\n","    data[col_name] = data.events.apply(lambda e: event_kind in e)\n","data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2VY052fE1HS"},"source":["data.rain"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cb4SzGsVE1HS"},"source":["data.rain.sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQlYrKVeE1HT"},"source":["data[data.rain & data.snow]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5swx9RUgE1HT"},"source":["def toCel(degree):\n","    return (degree - 32) / 1.8\n","    \n","data[\"max_tempc\"] = data.max_temp.apply(lambda e: toCel(e))\n","data[\"min_tempc\"] = data.min_temp.apply(lambda e: toCel(e))\n","data[\"mean_tempc\"] = data.mean_temp.apply(lambda e: toCel(e))\n","data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_WGTqUVE1HT"},"source":["### 1.9 Plotting"]},{"cell_type":"code","metadata":{"id":"unlCWK_XE1HT"},"source":["data.mean_tempc.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sV8nwqXE1HT"},"source":["data.mean_tempc.tail(10).plot(kind=\"bar\", rot=15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y2NvyGScE1HT"},"source":["다음의 그래프는 여러개 데이터의 그래프를 그려준다."]},{"cell_type":"code","metadata":{"id":"LDvxuAD8E1HT"},"source":["ax = data.max_temp.plot(title=\"Min and Max Temperatures\")\n","data.min_temp.plot(style=\"red\")\n","data.mean_temp.plot(style=\"yellow\")\n","ax.set_ylabel(\"Temperature (F)\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e6tszb2lE1HT"},"source":["### 1.10 Export Data\n","\n","`to_csv()` 함수는 데이터프레임을 CSV형태로 저장한다."]},{"cell_type":"code","metadata":{"id":"qFeI0ZyIE1HT"},"source":["data.to_csv(\"/content/drive/MyDrive/_SocialComp_2022-Lab/Week5/weather-mod.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uPi-h87sE1HT"},"source":["## 2.실습"]},{"cell_type":"markdown","metadata":{"id":"zYQrEuqOE1HT"},"source":["### 2.1 실습 1\n","* 주어진 employment.csv파일은 header가 없는 파일이다. 불러온 후 column의 header를 추가한다.\n","* 국가명을 인덱스로 지정한다.\n","* 불필요한 컬럼이 있으면 삭제한다.\n","* 상위 5개를 출력한다."]},{"cell_type":"code","metadata":{"id":"ul_kl11gE1HT"},"source":["import pandas as pd\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"btNbImeAE1HT"},"source":["### 2.2 실습 2\n","* 나머지 2개의 파일은 비슷한 구조로 되어 있어 employment.csv와 유사한 방법으로 불러오게 된다. 함수를 만들고 나머지 파일을 불러오자.\n","* life_expectancy.csv\n","* gdp_per_capita.csv"]},{"cell_type":"code","metadata":{"id":"Lz-ju6ofE1HT"},"source":["def read_gapminder_data(filename, colname):\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2sLrne8E1HU"},"source":["life_exp = read_gapminder_data(\"life_expectancy.csv\", \"life_exp\")\n","life_exp.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrPxyMulE1HU"},"source":["gdp = read_gapminder_data(\"gdp_per_capita.csv\", \"gdp\")\n","gdp.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OIcGmYrfE1HU"},"source":["### 2.3 실습 3\n","* 세개의 데이터프레임을 하나로 합치자.\n","* 데이터프레임을 합칠 때는 merge, join 등의 개념이 사용된다.\n","* http://pandas.pydata.org/pandas-docs/stable/merging.html 를 참고하자.\n","* (힌트) concat 이 사용된다."]},{"cell_type":"code","metadata":{"id":"WH1zkr0SE1HU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dz2FHQ4oE1HU"},"source":["소팅을 해보자. 소팅은 다음과 같이 한다.\n","* data.sort_values([colname1, colname2, ...], ascending=[True, False, ...])"]},{"cell_type":"code","metadata":{"id":"x3DbfKDJE1HU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bi5Naub0E1HU"},"source":["### 2.4 실습 4\n","* 전체 데이터프레임의 기술통계값을 출력하고 그래프를 그려보자.\n","* employment와 life_exp의 histogram을 그려보자."]},{"cell_type":"code","metadata":{"id":"_e2NLedxE1HU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mU3_jqDhE1HU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYTeU4uJE1HU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BnqwPtqWE1HU"},"source":["### 2.5 실습 5-1\n","* employment rate이 가장 높은 나라와 가장 낮은 나라의 이름과 값을 출력하자.\n","* 구글검색 혹은 레퍼런스를 통해 가장 높은 값과 낮은 값을 가진 인덱스를 출력하는 함수를 찾아 적용해보자.\n","\n","(검색어 예) pandas dataframe max index"]},{"cell_type":"code","metadata":{"id":"Ou9heg73E1HU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0g_U7sDLE1HU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BFP8dHh8E1HV"},"source":["### 2.6 실습 5-2\n","* gdp 상위 10개 국가의 평균과 하위 10개 국가의 리스트와 값을 구하고 그리고 평균의 차이를 구해보자.\n","* `sort_values()` 사용"]},{"cell_type":"code","metadata":{"id":"jglu-NtVE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hCnW9QxE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SPTU5x6E1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OD0NAL4bE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cNCYZZNIE1HV"},"source":["### 2.7 실습 5-3\n","* gpd 상위 10개 국가의 기대수명과 취업률 평균을 구하고 하위 10개 국가의 기대수명과 취업률 평균과 비교해 보자."]},{"cell_type":"code","metadata":{"id":"QyaTIyPmE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckESHO3AE1HV"},"source":["### 2.8 실습 6-1\n","* 각 국가의 초등학교 수료율을 기록한 두개의 파일을 읽어 하나의 데이터프레임을 만들어 보자.\n","* 남자의 초등학교 수료율: male_completion_rate.csv\n","* 여자의 초등학교 수료율: female_completion_rate.csv"]},{"cell_type":"code","metadata":{"id":"b1c5UgbdE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PFrUgADtE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pvIEJmRME1HV"},"source":["### 2.9 실습 6-2\n","* 초등학교 수료율이 남성보다 여성이 더 높은 나라를 찾아보자.\n","* 초등학교 수료율이 여성보다 남성이 더 높은 나라를 찾아보자."]},{"cell_type":"code","metadata":{"id":"iG7itlaoE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNtYl2P0E1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d33o7R1lE1HV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ee5giZMDE1HW"},"source":["### 2.10 실습 6-3\n","* 남성과 여성 간의 초등학교 수료율 차이가 큰 상위 20개의 나라를 찾아보자. (Top10 vs Botton10)"]},{"cell_type":"code","metadata":{"id":"tKTzmqbIE1HW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-D0J8ogE1HW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loAYQF0wE1HW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2WP_Q4V6E1HW"},"source":[""],"execution_count":null,"outputs":[]}]}